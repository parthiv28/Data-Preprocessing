# -*- coding: utf-8 -*-
"""Data Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HCCUsEAaRgVQ2-8u6q7fCXZNrqGLVFcb

#Data Preprocessing
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pandas as pd
import io
data = pd.read_csv('coffee_dataset.csv')
data.info()

data.head()

from sklearn.preprocessing import LabelEncoder , OneHotEncoder
data['Species'].value_counts()

"""#1. Label Encoder"""

le=LabelEncoder()
data['Number.of.Bags']=le.fit_transform(data['Number.of.Bags'])
data['Number.of.Bags'].value_counts()

le.classes_

"""#2. Onehot Encoder"""

data['In.Country.Partner'].value_counts()

one_hot = OneHotEncoder()
transformed_data = one_hot.fit_transform(data['In.Country.Partner'].values.reshape(-1,1)).toarray()
one_hot.categories_

transformed_data = pd.DataFrame(transformed_data , 
                                columns = ['AMECAFE', 'Africa Fine Coffee Association', 'Almacafé',
        'Asociacion Nacional Del Café',
        'Asociación Mexicana De Cafés y Cafeterías De Especialidad A.C.',
        'Asociación de Cafés Especiales de Nicaragua',
        'Blossom Valley International', 'Blossom Valley International\n',
        'Brazil Specialty Coffee Association',
        'Central De Organizaciones Productoras De Café y Cacao Del Perú - Central Café & Cacao',
        'Centro Agroecológico del Café A.C.', 'Coffee Quality Institute',
        'Ethiopia Commodity Exchange', 'Instituto Hondureño del Café',
        'Kenya Coffee Traders Association',
        'METAD Agricultural Development plc', 'NUCOFFEE',
        'Salvadoran Coffee Council', 'Specialty Coffee Ass',
        'Specialty Coffee Association',
        'Specialty Coffee Association of Costa Rica',
        'Specialty Coffee Association of Indonesia',
        'Specialty Coffee Institute of Asia', 'Tanzanian Coffee Board',
        'Torch Coffee Lab Yunnan', 'Uganda Coffee Development Authority',
        'Yunnan Coffee Exchange'])
transformed_data.head()

transformed_data.iloc[90, ]

data['Number.of.Bags'][90]

"""#Normalization & Standardization"""

numeric_columns = [c for c in data.columns if data[c].dtype != np.dtype('O')]
numeric_columns

len(numeric_columns) , len(data.columns)

numeric_columns.remove('Aroma')
numeric_columns.remove('Flavor')

temp_data = data[numeric_columns]
temp_data

"""#Normalization"""

from sklearn.preprocessing import StandardScaler , MinMaxScaler
import warnings
warnings.filterwarnings('ignore')
normalizer = MinMaxScaler()
temp_data.dropna(axis = 1 , inplace = True)
normalized_data = normalizer.fit_transform(temp_data)
pd.DataFrame(normalized_data , columns = temp_data.columns)

"""#Standardization"""

standard_scaler = StandardScaler()
standardized_data = standard_scaler.fit_transform(temp_data)
pd.DataFrame(standardized_data , columns = temp_data.columns)

"""#Handling With Missing Values"""

data.isnull().sum()

data['altitude_low_meters'].isnull().sum()

"""#Simple Imputer"""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan , strategy='mean')
agent_col = imputer.fit_transform(data['altitude_low_meters'].values.reshape(-1,1))
pd.DataFrame(agent_col).isnull().sum()

data['altitude_low_meters'].isnull().sum()

"""#Discretization"""

from sklearn.preprocessing import KBinsDiscretizer
temp_data.head()

"""#Quantile Discretization Transform"""

trans = KBinsDiscretizer(n_bins =10 , encode = 'ordinal' , strategy='quantile')
new_data = trans.fit_transform(temp_data)
pd.DataFrame(new_data,columns = temp_data.columns )

"""#Uniform Discretization Transform"""

trans = KBinsDiscretizer(n_bins =10 , encode = 'ordinal' , strategy='uniform')
new_data = trans.fit_transform(temp_data)

pd.DataFrame(new_data,columns = temp_data.columns )

"""#KMeans Discretization Transform"""

trans = KBinsDiscretizer(n_bins =10 , encode = 'ordinal' , strategy='kmeans')
new_data = trans.fit_transform(temp_data)

pd.DataFrame(new_data,columns = temp_data.columns )